{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ–‡æ¡£åˆ‡åˆ†\n",
    "***\n",
    "- æŒ‰ç…§é•¿åº¦åˆ‡åˆ†\n",
    "- æŒ‰ç…§æ–‡æœ¬æ¶æ„è¿›è¡Œåˆ‡åˆ†ï¼ˆå¥å­ã€æ®µè½ï¼‰\n",
    "- æŒ‰ç…§æ–‡æ¡£æ ¼å¼åˆ‡åˆ†\n",
    "- åŸºäºè¯­ä¹‰è¿›è¡Œåˆ‡åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é•¿åº¦åˆ‡åˆ†\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='deepseek.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2. ç®—â¼’éœ€æ±‚åˆ†æ\\næ¨¡å‹ å‚æ•°è§„\\næ¨¡\\nè®¡ç®—ç²¾\\nåº¦\\næœ€ä½æ˜¾å­˜éœ€\\næ±‚ æœ€ä½ç®—â¼’éœ€æ±‚\\nDeepSeek-R1 (671B)671B FP8 â‰¥890GB 2*XE9680ï¼ˆ16*H20\\nGPUï¼‰\\nDeepSeek-R1-Distill-\\n70B 70B BF16 â‰¥180GB 4*L20 æˆ– 2*H20 GPU\\nä¸‰ã€å›½äº§èŠ¯â½šä¸ç¡¬ä»¶é€‚é…â½…æ¡ˆ\\n1. å›½å†…â½£æ€åˆä½œä¼™ä¼´åŠ¨æ€\\nä¼ä¸š é€‚é…å†…å®¹ æ€§èƒ½å¯¹æ ‡ï¼ˆvs\\nNVIDIAï¼‰\\nåä¸ºæ˜‡\\nè…¾\\næ˜‡è…¾910BåŸâ½£â½€æŒR1å…¨ç³»åˆ—ï¼Œæä¾›ç«¯åˆ°ç«¯æ¨ç†ä¼˜åŒ–\\nâ½…æ¡ˆ ç­‰æ•ˆA100ï¼ˆFP16ï¼‰\\næ²æ›¦\\nGPU\\nMXNç³»åˆ—â½€æŒ70Bæ¨¡å‹BF16æ¨ç†ï¼Œæ˜¾å­˜åˆ©â½¤ç‡æå‡\\n30% ç­‰æ•ˆRTX 3090\\næµ·å…‰\\nDCU é€‚é…V3/R1æ¨¡å‹ï¼Œæ€§èƒ½å¯¹æ ‡NVIDIA A100 ç­‰æ•ˆA100ï¼ˆBF16ï¼‰\\n2. å›½äº§ç¡¬ä»¶æ¨èé…ç½®\\næ¨¡å‹å‚æ•° æ¨èâ½…æ¡ˆ é€‚â½¤åœºæ™¯\\n1.5B å¤ªåˆT100åŠ é€Ÿå¡ ä¸ªâ¼ˆå¼€å‘è€…åŸå‹éªŒè¯\\n14B æ˜†ä»‘èŠ¯K200é›†ç¾¤ ä¼ä¸šçº§å¤æ‚ä»»åŠ¡æ¨ç†\\n32B å£å½»ç®—â¼’å¹³å°+æ˜‡è…¾910Bé›†ç¾¤ ç§‘ç ”è®¡ç®—ä¸å¤šæ¨¡æ€å¤„ç†\\nå››ã€äº‘ç«¯éƒ¨ç½²æ›¿ä»£â½…æ¡ˆ\\n1. å›½å†…äº‘æœåŠ¡å•†æ¨è\\nå¹³å° æ ¸â¼¼ä¼˜åŠ¿ é€‚â½¤åœºæ™¯']\n",
      "[Document(metadata={}, page_content='ç¡…åŸºæµåŠ¨ å®˜â½…æ¨èAPIï¼Œä½å»¶è¿Ÿï¼Œâ½€æŒå¤šæ¨¡æ€æ¨¡å‹ ä¼ä¸šçº§â¾¼å¹¶å‘æ¨ç†\\nè…¾è®¯äº‘ â¼€é”®éƒ¨ç½²+é™æ—¶å…è´¹ä½“éªŒï¼Œâ½€æŒVPCç§æœ‰åŒ– ä¸­â¼©è§„æ¨¡æ¨¡å‹å¿«é€Ÿä¸Šçº¿\\nPPIOæ´¾æ¬§äº‘ ä»·æ ¼ä»…ä¸ºOpenAI 1/20ï¼Œæ³¨å†Œèµ 5000ä¸‡tokens ä½æˆæœ¬å°é²œä¸æµ‹è¯•\\n2. å›½é™…æ¥â¼Šæ¸ é“ï¼ˆéœ€é­”æ³•æˆ–å¤–ä¼ä¸Šâ½¹ç¯å¢ƒ\\n!\\nï¼‰\\nè‹±ä¼Ÿè¾¾NIMï¼šä¼ä¸šçº§GPUé›†ç¾¤éƒ¨ç½²ï¼ˆé“¾æ¥ï¼‰\\nGroqï¼šè¶…ä½å»¶è¿Ÿæ¨ç†ï¼ˆé“¾æ¥ï¼‰\\näº”ã€å®Œæ•´671B MoEæ¨¡å‹éƒ¨ç½²ï¼ˆOllama+Unslothï¼‰\\n1. é‡åŒ–â½…æ¡ˆä¸æ¨¡å‹é€‰æ‹©\\né‡åŒ–ç‰ˆæœ¬ â½‚ä»¶ä½“\\nç§¯\\næœ€ä½å†…å­˜+æ˜¾å­˜éœ€\\næ±‚ é€‚â½¤åœºæ™¯\\nDeepSeek-R1-UD-\\nIQ1_M 158 GB â‰¥200 GB æ¶ˆè´¹çº§ç¡¬ä»¶ï¼ˆå¦‚Mac\\nStudioï¼‰\\nDeepSeek-R1-Q4_K_M 404 GB â‰¥500 GB â¾¼æ€§èƒ½æœåŠ¡å™¨/äº‘GPU\\nä¸‹è½½åœ°å€ï¼š\\nHuggingFaceæ¨¡å‹åº“\\nUnsloth AIå®˜â½…è¯´æ˜\\n2. ç¡¬ä»¶é…ç½®å»ºè®®\\nç¡¬ä»¶ç±»å‹ æ¨èé…ç½® æ€§èƒ½è¡¨ç°ï¼ˆçŸ­â½‚æœ¬â½£æˆï¼‰\\næ¶ˆè´¹çº§è®¾å¤‡ Mac Studioï¼ˆ192GBç»Ÿâ¼€å†…å­˜ï¼‰ 10+ token/ç§’\\nâ¾¼æ€§èƒ½æœåŠ¡å™¨4Ã—RTX 4090ï¼ˆ96GBæ˜¾å­˜+384GBå†…å­˜ï¼‰ 7-8 token/ç§’ï¼ˆæ··åˆæ¨ç†ï¼‰\\n3. éƒ¨ç½²æ­¥éª¤ï¼ˆLinuxç¤ºä¾‹ï¼‰\\n1. å®‰è£…ä¾èµ–â¼¯å…·ï¼š\\n# å®‰è£…llama.cppï¼ˆâ½¤äºåˆå¹¶åˆ†â½šâ½‚ä»¶ï¼‰\\n/bin/bash -c \"$(curl -fsSL \\nhttps://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\\nbrew install llama.cpp'), Document(metadata={}, page_content='2. ä¸‹è½½å¹¶åˆå¹¶æ¨¡å‹åˆ†â½šï¼š\\n3. å®‰è£…Ollamaï¼š\\n4. åˆ›å»ºModelfileï¼š\\n5. è¿â¾æ¨¡å‹ï¼š\\n4. æ€§èƒ½è°ƒä¼˜ä¸æµ‹è¯•\\nGPUåˆ©â½¤ç‡ä½ï¼šå‡çº§â¾¼å¸¦å®½å†…å­˜ï¼ˆå¦‚DDR5 5600+ï¼‰ã€‚\\næ‰©å±•äº¤æ¢ç©ºé—´ï¼š\\nå…­ã€æ³¨æ„äº‹é¡¹ä¸â»›é™©æç¤º\\n1. æˆæœ¬è­¦ç¤ºï¼š\\n70Bæ¨¡å‹ï¼šéœ€3å¼ ä»¥ä¸Š80Gæ˜¾å­˜æ˜¾å¡ï¼ˆå¦‚RTX A6000ï¼‰ï¼Œå•å¡â½¤æˆ·ä¸å¯â¾ã€‚\\n671Bæ¨¡å‹ï¼šéœ€8xH100é›†ç¾¤ï¼Œä»…é™è¶…ç®—ä¸­â¼¼éƒ¨ç½²ã€‚\\n2. æ›¿ä»£â½…æ¡ˆï¼š\\nä¸ªâ¼ˆâ½¤æˆ·æ¨èä½¿â½¤äº‘ç«¯APIï¼ˆå¦‚ç¡…åŸºæµåŠ¨ï¼‰ï¼Œå…è¿ç»´ä¸”åˆè§„ã€‚\\n3. å›½äº§ç¡¬ä»¶å…¼å®¹æ€§ï¼šéœ€ä½¿â½¤å®šåˆ¶ç‰ˆæ¡†æ¶ï¼ˆå¦‚æ˜‡è…¾CANNã€æ²æ›¦MXMLLMï¼‰ã€‚\\nllama-gguf-split --merge DeepSeek-R1-UD-IQ1_M-00001-of-00004.gguf \\nDeepSeek-R1-UD-IQ1_S.gguf\\ncurl -fsSL https://ollama.com/install.sh | sh\\nFROM /path/to/DeepSeek-R1-UD-IQ1_M.gguf  \\nPARAMETER num_gpu 28  # æ¯å—RTX 4090åŠ è½½7å±‚ï¼ˆå…±4å¡ï¼‰  \\nPARAMETER num_ctx 2048  \\nPARAMETER temperature 0.6  \\nTEMPLATE \"<ï½œendâ–ofâ–thinkingï½œ>{{ .Prompt }}<ï½œendâ–ofâ–thinkingï½œ>\"\\nollama create DeepSeek-R1-UD-IQ1_M -f DeepSeekQ1_Modelfile\\nollama run DeepSeek-R1-UD-IQ1_M --verbose\\nsudo fallocate -l 100G /swapfile\\nsudo chmod 600 /swapfile\\nsudo mkswap /swapfile\\nsudo swapon /swapfile')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=50, chunk_overlap=10\n",
    ")\n",
    "texts = text_splitter.split_text(pages[1].page_content)\n",
    "print(texts)\n",
    "docs = text_splitter.create_documents([pages[2].page_content,pages[3].page_content])\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŸºäºæ–‡æœ¬æ¶æ„\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2. ç®—â¼’éœ€æ±‚åˆ†æ\\næ¨¡å‹ å‚æ•°è§„\\næ¨¡\\nè®¡ç®—ç²¾\\nåº¦\\næœ€ä½æ˜¾å­˜éœ€\\næ±‚ æœ€ä½ç®—â¼’éœ€æ±‚', 'DeepSeek-R1 (671B)671B FP8 â‰¥890GB 2*XE9680ï¼ˆ16*H20', 'GPUï¼‰\\nDeepSeek-R1-Distill-', '70B 70B BF16 â‰¥180GB 4*L20 æˆ– 2*H20 GPU', 'ä¸‰ã€å›½äº§èŠ¯â½šä¸ç¡¬ä»¶é€‚é…â½…æ¡ˆ\\n1. å›½å†…â½£æ€åˆä½œä¼™ä¼´åŠ¨æ€\\nä¼ä¸š é€‚é…å†…å®¹ æ€§èƒ½å¯¹æ ‡ï¼ˆvs', 'NVIDIAï¼‰\\nåä¸ºæ˜‡\\nè…¾\\næ˜‡è…¾910BåŸâ½£â½€æŒR1å…¨ç³»åˆ—ï¼Œæä¾›ç«¯åˆ°ç«¯æ¨ç†ä¼˜åŒ–', 'â½…æ¡ˆ ç­‰æ•ˆA100ï¼ˆFP16ï¼‰\\næ²æ›¦\\nGPU\\nMXNç³»åˆ—â½€æŒ70Bæ¨¡å‹BF16æ¨ç†ï¼Œæ˜¾å­˜åˆ©â½¤ç‡æå‡', '30% ç­‰æ•ˆRTX 3090\\næµ·å…‰', 'DCU é€‚é…V3/R1æ¨¡å‹ï¼Œæ€§èƒ½å¯¹æ ‡NVIDIA A100 ç­‰æ•ˆA100ï¼ˆBF16ï¼‰', '2. å›½äº§ç¡¬ä»¶æ¨èé…ç½®\\næ¨¡å‹å‚æ•° æ¨èâ½…æ¡ˆ é€‚â½¤åœºæ™¯', '1.5B å¤ªåˆT100åŠ é€Ÿå¡ ä¸ªâ¼ˆå¼€å‘è€…åŸå‹éªŒè¯\\n14B æ˜†ä»‘èŠ¯K200é›†ç¾¤ ä¼ä¸šçº§å¤æ‚ä»»åŠ¡æ¨ç†', '32B å£å½»ç®—â¼’å¹³å°+æ˜‡è…¾910Bé›†ç¾¤ ç§‘ç ”è®¡ç®—ä¸å¤šæ¨¡æ€å¤„ç†\\nå››ã€äº‘ç«¯éƒ¨ç½²æ›¿ä»£â½…æ¡ˆ', '1. å›½å†…äº‘æœåŠ¡å•†æ¨è\\nå¹³å° æ ¸â¼¼ä¼˜åŠ¿ é€‚â½¤åœºæ™¯']\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(pages[1].page_content)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åŸºäºæ–‡æ¡£æ¶æ„\n",
    "****\n",
    "- markdown æ ¹æ®æ ‡é¢˜æ‹†åˆ†ï¼ˆä¾‹å¦‚ï¼Œ#ã€##ã€###ï¼‰\n",
    "- JSONï¼šæŒ‰å¯¹è±¡æˆ–æ•°ç»„å…ƒç´ æ‹†åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŸºäºmarkdownæ ¼å¼è¿›è¡Œåˆ‡åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar'}, page_content='Hi this is Jim  \\nHi this is Joe'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar', 'Header 3': 'Boo'}, page_content='Hi this is Lance'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Baz'}, page_content='Hi this is Molly')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "markdown_document = \"# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŸºäºJSONæ ¼å¼è¿›è¡Œåˆ‡åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openapi': '3.1.0', 'info': {'title': 'LangSmith', 'version': '0.1.0'}, 'paths': {'/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'], 'summary': 'Read Tracer Session', 'description': 'Get a specific session.'}}}}\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'operationId': 'read_tracer_session_api_v1_sessions__session_id__get', 'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}}\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id', 'in': 'path', 'required': True, 'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}, {'name': 'include_stats', 'in': 'query', 'required': False, 'schema': {'type': 'boolean', 'default': False, 'title': 'Include Stats'}}, {'name': 'accept', 'in': 'header', 'required': False, 'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Accept'}}]}}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=300)\n",
    "json_chunks = splitter.split_json(json_data=json_data)\n",
    "\n",
    "for chunk in json_chunks[:3]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"operationId\": \"read_tracer_session_api_v1_sessions__session_id__get\", \"security\": [{\"API Key\": []}, {\"Tenant ID\": []}, {\"Bearer Auth\": []}]}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}'\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆlangchain Document\n",
    "docs = splitter.create_documents(texts=[json_data])\n",
    "\n",
    "for doc in docs[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åŸºäºè¯­ä¹‰åˆ‡åˆ†\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"meow.txt\") as f:\n",
    "    meow = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "# ä½¿ç”¨OpenAIEmbeddingsè¿›è¡Œå‘é‡åŒ–\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meow meowğŸ± \n",
      " meow meowğŸ± \n",
      " meowğŸ˜»ğŸ˜»\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([meow])\n",
    "print(docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
